# Beyond EDA: Intelligent Data Cleaning & Preprocessing with LLM-Powered Imputation

This project focuses on **data cleaning**, **exploratory data analysis (EDA)**, and **preprocessing** steps for a customer churn dataset, preparing it for downstream machine learning tasks. The dataset contains customer demographic and account information with the goal of understanding churn patterns.

## ğŸ“ Project Structure

EDA/data/<br>
â”œâ”€â”€ processed/<br>
â”œâ”€â”€ raw/<br>
<br>
ğŸ“„ .env <br>
ğŸ“„ .gitignore <br>
ğŸ“’ 0_handle_missing_values.ipynb <br>
ğŸ“’ 1_handling_outliers.ipynb <br>
ğŸ“’ 2_feature_binning.ipynb <br>
ğŸ“’ 3_feature_encoding.ipynb <br>
ğŸ“’ 4_feature_scaling.ipynb <br>
ğŸ“„ README.md <br>
ğŸ“„ requirements.txt <br>

## ğŸ§¾ Steps Covered

- âœ… Standard setup and dataset loading  
- âœ… Handling **missing values**
- âœ… Visualizing numerical data with **boxplots**
- âœ… Exploring categorical data with **pie charts**
- âœ… Outlier detection using:
  - **Empirical Rule (Three Sigma Rule)**
  - **IQR Method**
- âœ… Logging and flagging of outliers (not removed until business confirmation)
- âœ… Saving the cleaned dataset after handling missing values
- âœ… **Feature Binning** (e.g., converting Credit Score to categories like Poor, Good, Excellent)
- âœ… **Feature Encoding** for nominal variables using One-Hot Encoding
- âœ… **Feature Scaling** with standardization techniques to normalize numerical features

## ğŸ§  Beyond EDA with LLMs

Large Language Models (LLMs) like ChatGPT were used to:
- Accelerate explanation of data exploration steps  
- Generate clean, readable summaries of code and logic  
- Provide instant support during debugging and documentation  
- Suggest next steps for feature engineering and modeling

This approach blends traditional EDA with modern AI-assisted workflows to increase both **speed** and **clarity**.

## ğŸ› ï¸ Technologies Used

- Python ğŸ
- Pandas
- NumPy
- Matplotlib
- Seaborn
- Scikit-learn
- ChatGPT / LLMs for code assistance and documentation

## ğŸ“Œ Notes

- Outliers were **only identified**, not removed, as further validation is needed from business stakeholders.
- Cleaned datasets are saved in the `data/processed/` folder for easy access and reuse.

## ğŸ“‚ Next Steps

- Feature Selection  
- Model Building (Classification)

---

Feel free to clone or fork this project and adapt it for your own EDA workflows.
